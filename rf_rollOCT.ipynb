{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.ensemble import BaseEnsemble\n",
    "from scipy.stats import mode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24061e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rolling_lookahead_dt_pulp import rollo_oct_pulp\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "#from rolling_lookahead_dt_pulp.oct.optimal_tree_pulp import predict_model_pulp\n",
    "\n",
    "from rolling_lookahead_dt_pulp.rolling_tree.rolling_optimize_pulp import rolling_optimize_pulp\n",
    "from rolling_lookahead_dt_pulp.oct.tree import *\n",
    "from rolling_lookahead_dt_pulp.oct.optimal_tree_pulp import *\n",
    "from helpers.helpers import preprocess_dataframes\n",
    "\n",
    "# was hiermit eben nicht geht ist, dass man auf Trainingsdaten trainiert (was einem das reine Modell geben sollte). Dabei werden aber leider gleichzeitig\n",
    "# die Testdaten auf diesen Modell predicted\n",
    "# Das Resultat ist also, dass man nicht andere Testdaten auf dem fertigen modell testen kann\n",
    "\n",
    "class CustomTreeWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, train_data, test_data, depth=None, criterion='gini', target_label=None, features=None, time_limit = 1800, big_m = 99):\n",
    "        self.depth = depth\n",
    "        self.criterion = criterion\n",
    "        self.test_data = test_data\n",
    "        self.train_data = train_data\n",
    "        self.target_label = target_label\n",
    "        self.features = features\n",
    "        self.time_limit = time_limit\n",
    "        self.big_m = big_m\n",
    "        self.construct()\n",
    "\n",
    "    def construct(self):\n",
    "        train, test = preprocess_dataframes( #./rollo_oct/utils/helpers.py\n",
    "        train_df = self.train_data,\n",
    "        test_df = self.test_data,\n",
    "        target_label = self.target_label,\n",
    "        features = self.features)\n",
    "\n",
    "        df = pd.concat([train, test])\n",
    "        self.P = [int(i) for i in\n",
    "            list(train.loc[:, train.columns != 'y'].columns)]\n",
    "        train.columns = [\"y\", *self.P]\n",
    "        test.columns = [\"y\", *self.P]\n",
    "        self.K = sorted(list(set(df.y)))\n",
    "\n",
    "        self.result_dict = {} #adding dict to store solutions for every level\n",
    "        self.result_dict['tree'] = {}\n",
    "        self.result_dict['tree'][2] = {}\n",
    "        \n",
    "        # generate model\n",
    "        self.main_model = generate_model_pulp(P=self.P, K=self.K, data=train, y_idx=0, big_m=self.big_m, criterion=self.criterion)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.train_data = pd.concat([y, X], axis=1, ignore_index=False)\n",
    "\n",
    "        train, test = preprocess_dataframes( #./rollo_oct/utils/helpers.py\n",
    "                                            train_df = self.train_data,\n",
    "                                            test_df = self.test_data,\n",
    "                                            target_label = self.target_label,\n",
    "                                            features = self.features)\n",
    "        \n",
    "        self.P = [int(i) for i in \n",
    "            list(train.loc[:, train.columns != 'y'].columns)]\n",
    "        \n",
    "        self.main_model = train_model_pulp(model_dict=self.main_model, data=train, P=self.P)\n",
    "\n",
    "        self.result_dict['tree'][2]['trained_dict'] = self.main_model\n",
    "\n",
    "        # predict model\n",
    "        result_train = predict_model_pulp(data=train, model_dict=self.main_model, P=self.P)\n",
    "\n",
    "        misclassified_leafs = find_misclassification(df=result_train)\n",
    "\n",
    "        result_test = predict_model_pulp(data=test, model_dict=self.main_model, P=self.P)\n",
    "        \n",
    "        \n",
    "        train_acc = len(result_train.loc[result_train[\"prediction\"] == result_train[\"y\"]]) / \\\n",
    "                    len(result_train[\"y\"])\n",
    "\n",
    "        test_acc = len(result_test.loc[result_test[\"prediction\"] == result_test[\"y\"]]) / \\\n",
    "                len(result_test[\"y\"])\n",
    "        \n",
    "        \n",
    "        self.result_dict['tree'][2]['train'] = result_train[['y', 'prediction', 'leaf']]\n",
    "        self.result_dict['tree'][2]['test'] = result_test[['y', 'prediction', 'leaf']]\n",
    "\n",
    "        self.result_dict[2] = {\n",
    "        \"training_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc\n",
    "        }\n",
    "\n",
    "        train = train.drop([\"prediction\", \"leaf\"], axis=1)\n",
    "        test = test.drop([\"prediction\", \"leaf\"], axis=1)\n",
    "\n",
    "        if self.depth > 2:\n",
    "            self.result_dict = rolling_optimize_pulp(predefined_model=self.main_model,\n",
    "                                            train_data=train,\n",
    "                                            test_data=test,\n",
    "                                            main_depth=2,\n",
    "                                            target_depth=self.depth,\n",
    "                                            features=self.P,\n",
    "                                            time_limit=self.time_limit,\n",
    "                                            to_go_deep_nodes=misclassified_leafs,\n",
    "                                            result_dict=self.result_dict,\n",
    "                                            criterion=self.criterion)\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "\n",
    "        #print(X)\n",
    "\n",
    "        model_dict = self.result_dict['tree'][self.depth]['trained_dict']\n",
    "\n",
    "        dummy = pd.DataFrame({'y': [None]*len(X)}, index=X.index)\n",
    "\n",
    "        test = pd.concat([dummy, X], axis=1)\n",
    "\n",
    "        #print(test)\n",
    "\n",
    "        res = predict_model_pulp(data=test, model_dict=model_dict, P=self.P)\n",
    "\n",
    "        #print(res)\n",
    "        \n",
    "        preds = res['prediction']\n",
    "        if preds is None:\n",
    "            raise RuntimeError(\"No stored predictions found. Run fit first.\")\n",
    "        \n",
    "        #check = self.result_dict['tree'][self.depth]['test']\n",
    "        #check = check.drop(columns=['y', 'leaf'])\n",
    "        #print(check)\n",
    "\n",
    "        #print(preds.equals(check['prediction']))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f3d02",
   "metadata": {},
   "source": [
    "Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from scipy.stats import mode\n",
    "\n",
    "class CustomEnsembleClassifier:\n",
    "    def __init__(self, n_estimators=10, tree_kwargs=None, random_state=None):\n",
    "        \"\"\"\n",
    "        n_estimators: number of trees in the ensemble\n",
    "        tree_kwargs: dictionary of keyword args for CustomTreeWrapper (except train_data and test_data)\n",
    "        random_state: seed for reproducible bootstrap sampling\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.tree_kwargs = tree_kwargs if tree_kwargs is not None else {}\n",
    "        self.random_state = random_state\n",
    "        self.trees_ = []\n",
    "        self.bootstrap_indices_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: pd.DataFrame of features\n",
    "        y: pd.Series of target labels\n",
    "        \"\"\"\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        self.trees_ = []\n",
    "        self.bootstrap_indices_ = []\n",
    "\n",
    "        indices = np.array(X.index)\n",
    "        for i in range(self.n_estimators):\n",
    "            # Bootstrap sample indices\n",
    "            sample_indices = rng.choice(indices, size=len(indices), replace=True)\n",
    "            oob_mask = ~np.in1d(indices, sample_indices)\n",
    "            oob_indices = indices[oob_mask]\n",
    "            self.bootstrap_indices_.append((sample_indices, oob_indices))\n",
    "\n",
    "            # Create train_data DataFrame: target as first column, features with integer columns\n",
    "            X_boot = X.loc[sample_indices]\n",
    "            y_boot = y.loc[sample_indices]\n",
    "            train_data = pd.concat([y_boot, X_boot], axis=1)\n",
    "            train_data.columns = ['y'] + list(range(X.shape[1]))\n",
    "\n",
    "            # Out-of-bag for test_data\n",
    "            if len(oob_indices) > 0:\n",
    "                X_oob = X.loc[oob_indices]\n",
    "                y_oob = y.loc[oob_indices]\n",
    "                test_data = pd.concat([y_oob, X_oob], axis=1)\n",
    "                test_data.columns = ['y'] + list(range(X.shape[1]))\n",
    "            else:\n",
    "                # If somehow no oob sample, just use train_data (edge case)\n",
    "                test_data = train_data.copy()\n",
    "\n",
    "            # Initialize and fit the tree\n",
    "            tree = CustomTreeWrapper(train_data=train_data,\n",
    "                                     test_data=test_data,\n",
    "                                     **self.tree_kwargs)\n",
    "            tree.fit(X_boot, y_boot)\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Majority-vote ensemble prediction.\n",
    "        Returns: pd.Series with predictions, aligned to X.index\n",
    "        \"\"\"\n",
    "        # Aggregate predictions (each as Series aligned to X.index)\n",
    "        all_preds = []\n",
    "        for tree in self.trees_:\n",
    "            pred = tree.predict(X)\n",
    "            # ensure we have a Series matching X's index\n",
    "            if not isinstance(pred, pd.Series):\n",
    "                pred = pd.Series(pred, index=X.index)\n",
    "            all_preds.append(pred)\n",
    "        # Stack and compute mode along 0 axis\n",
    "        preds_matrix = pd.concat(all_preds, axis=1)\n",
    "        maj_vote = preds_matrix.mode(axis=1)[0]\n",
    "        maj_vote.index = X.index\n",
    "        return maj_vote\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        For binary classification:\n",
    "        Returns an array of shape (n_samples, 2)\n",
    "        \"\"\"\n",
    "        all_preds = []\n",
    "        for tree in self.trees_:\n",
    "            pred = tree.predict(X)\n",
    "            if not isinstance(pred, pd.Series):\n",
    "                pred = pd.Series(pred, index=X.index)\n",
    "            all_preds.append(pred)\n",
    "        preds_matrix = pd.concat(all_preds, axis=1)\n",
    "\n",
    "        # Works for binary or multiclass\n",
    "        classes_ = np.unique(preds_matrix.values)\n",
    "        proba = np.zeros((X.shape[0], len(classes_)))\n",
    "        for i, c in enumerate(classes_):\n",
    "            proba[:, i] = (preds_matrix == c).sum(axis=1) / self.n_estimators\n",
    "        return proba\n",
    "\n",
    "    def oob_score(self, X, y):\n",
    "        \"\"\"\n",
    "        Returns out-of-bag score.\n",
    "        \"\"\"\n",
    "        # Prepare OOB predictions\n",
    "        oob_votes = {idx: [] for idx in X.index}\n",
    "        for (sample_ind, oob_ind), tree in zip(self.bootstrap_indices_, self.trees_):\n",
    "            if len(oob_ind) == 0:\n",
    "                continue\n",
    "            X_oob = X.loc[oob_ind]\n",
    "            preds = tree.predict(X_oob)\n",
    "            for idx, pred in preds.items():\n",
    "                oob_votes[idx].append(pred)\n",
    "        # Only score samples with at least one OOB prediction\n",
    "        final_oob_preds = []\n",
    "        final_oob_true = []\n",
    "        for idx, votes in oob_votes.items():\n",
    "            if votes:\n",
    "                final_oob_preds.append(mode(votes)[0][0])\n",
    "                final_oob_true.append(y.loc[idx])\n",
    "        if not final_oob_preds:\n",
    "            raise ValueError(\"No OOB predictions collected.\")\n",
    "        accuracy = np.mean(np.array(final_oob_preds) == np.array(final_oob_true))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514caec",
   "metadata": {},
   "source": [
    "Testing Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_seismic = pd.read_csv(\"datasets/seismic/seismic_bin.csv\")\n",
    "\n",
    "\n",
    "X = data_seismic.drop(columns=['y'])  # All columns except the target\n",
    "y = data_seismic['y']                 # Only the target column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, stratify=y, random_state=42)\n",
    "\n",
    "stacked_train = pd.concat([y_train, X_train], axis=1, ignore_index=False)\n",
    "stacked_test = pd.concat([y_test, X_test],axis=1, ignore_index=False)\n",
    "\n",
    "train_data = stacked_train\n",
    "test_data = stacked_test\n",
    "\n",
    "#feature_columns = train_data.columns[1:]\n",
    "\n",
    "feature_columns = X_train.columns\n",
    "#print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c767c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage outside:\n",
    "wrapper = CustomTreeWrapper(\n",
    "    depth=3,\n",
    "    criterion='gini',\n",
    "    test_data=test_data,\n",
    "    train_data= train_data,\n",
    "    target_label='y',\n",
    "    features=feature_columns\n",
    ")\n",
    "wrapper.fit(X_train, y_train); #semicolon for suppressing when interactive environment (Jupyter) tries to display the returned object, suppresses repr(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13aad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = wrapper.predict(test_data)\n",
    "predictions = wrapper.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3879cb",
   "metadata": {},
   "source": [
    "Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you already have: X_train, X_test, y_train, y_test (pandas DataFrame/Series)\n",
    "tree_kwargs = dict(depth=3, criterion='gini', target_label='y', features=list(range(X_train.shape[1])))\n",
    "\n",
    "ensemble = CustomEnsembleClassifier(n_estimators=10, tree_kwargs=tree_kwargs, random_state=42)\n",
    "ensemble.fit(X_train, y_train)\n",
    "y_pred = ensemble.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
