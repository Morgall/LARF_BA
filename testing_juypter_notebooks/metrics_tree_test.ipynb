{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9a85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Go up one directory to get to master/\n",
    "project_root = str(Path.cwd().parent)\n",
    "sys.path.append(project_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549ba1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_available = 8\n",
    "name_dataset = \"adult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651eaef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  y  prediction  leaf\n",
      "0              3  1           1   447\n",
      "1              4  1           2   278\n",
      "2             15  1           1   433\n",
      "3             26  1           1   471\n",
      "4             40  1           1   439\n",
      "...          ... ..         ...   ...\n",
      "4879       48802  1           1   335\n",
      "4880       48805  2           1   423\n",
      "4881       48808  1           1   467\n",
      "4882       48822  2           2   285\n",
      "4883       48838  1           1   478\n",
      "\n",
      "[4884 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_solutions_all_folds_pulp(name_dataset: str, depth=3) -> pd.DataFrame: #for 10 fold cross valdidation, carefull that trees have min depth 2\n",
    "    sol_dict = {} # one entry for every fold, [fold][depth]['test'] for test_data classification for fold of depth; same for training\n",
    "    for i in range(1,11):\n",
    "        sol_dict[i] = {}\n",
    "        for j in range(2,depth+1):\n",
    "            sol_dict[i][j] = {}\n",
    "            sol_dict[i][j]['test'] = pd.read_csv(f\"../results/{name_dataset}/pulp/fold{i}/depth{j}_classification_{name_dataset}_test.csv\")\n",
    "            sol_dict[i][j]['train'] = pd.read_csv(f\"../results/{name_dataset}/pulp/fold{i}/depth{j}_classification_{name_dataset}_train.csv\")\n",
    "    return sol_dict\n",
    "\n",
    "sol_dict = get_solutions_all_folds_pulp(name_dataset=name_dataset, depth= max_depth_available)\n",
    "\n",
    "#print(sol_dict[4][8]['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3d4ba",
   "metadata": {},
   "source": [
    "damit das hier immer funktioniert, muss das mapping vom binarizer auf die Zahlen immer gleich sein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c4aaf",
   "metadata": {},
   "source": [
    "Achtung: Man muss noch in den Ergebnissen zuordnen was in den Ursprungsdatensatz (das binarized wurde) als positive und was als negative gesehen wird. Also wie das label jetzt heißt dem ursprünglichen label zuordnen\n",
    "\n",
    "=> Ich habe mich entschieden das schon beim binarizen zu machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          14    y\n",
      "0      <=50K  1.0\n",
      "1      <=50K  1.0\n",
      "2       >50K  1.0\n",
      "3       >50K  1.0\n",
      "4      <=50K  1.0\n",
      "...      ...  ...\n",
      "16276  <=50K  NaN\n",
      "16277  <=50K  NaN\n",
      "16278  <=50K  NaN\n",
      "16279  <=50K  NaN\n",
      "16280   >50K  NaN\n",
      "\n",
      "[16281 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# specifics for every dataset can of course vary\n",
    "\n",
    "if name_dataset == \"adult\": #we are looking to match <=50 and >50 to binary labels\n",
    "    # wie war das nochmal mit den Zuordnungen und warum mach ich hier nicht die Zuordnung über dem binarized dataset vor rollOCT\n",
    "    origin_dataset_test = pd.read_csv(f\"../datasets/{name_dataset}/adult.test\", sep=',', skipinitialspace=True, header=None) #16281 rows\n",
    "    # Remove dots from the 'target' column\n",
    "    origin_target_col = origin_dataset_test[14].astype(str).str.replace('.', '', regex=False) #in this dataset targets are in col 14\n",
    "    some_dataset_solution = sol_dict[1][max_depth_available]['test']\n",
    "    target_labels_col = some_dataset_solution['y']\n",
    "    df = pd.concat([origin_target_col, target_labels_col], axis=1)\n",
    "    print(df)\n",
    "    mapping = df.drop_duplicates().set_index('y')[14].to_dict() #this doesnt fail if number of rows dont match exactly. Missing col entries get NaN\n",
    "    #print(mapping)\n",
    "    #Convention for now: >50K is positive, <=50K is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35bdc692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        2\n",
      "3        2\n",
      "4        1\n",
      "        ..\n",
      "16276    1\n",
      "16277    1\n",
      "16278    1\n",
      "16279    1\n",
      "16280    2\n",
      "Name: y, Length: 16281, dtype: int64\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        2\n",
      "4        1\n",
      "        ..\n",
      "16276    1\n",
      "16277    1\n",
      "16278    2\n",
      "16279    1\n",
      "16280    2\n",
      "Name: prediction, Length: 16281, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(target_labels_col)\n",
    "print(prediction_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d2eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16281\n",
      "16281\n"
     ]
    }
   ],
   "source": [
    "def acc_sens_spec_prec(solution, pos_represent, neg_represent): #16281\n",
    "    tp = len(solution[(solution['y'] == pos_represent) & (solution['prediction'] == pos_represent)])\n",
    "    tn = len(solution[(solution['y'] == neg_represent) & (solution['prediction'] == neg_represent)])\n",
    "    fp = len(solution[(solution['y'] == neg_represent) & (solution['prediction'] == pos_represent)])\n",
    "    fn = len(solution[(solution['y'] == pos_represent) & (solution['prediction'] == neg_represent)])\n",
    "    number_datapoints = tp+tn+fp+fn\n",
    "    if number_datapoints != len(solution):\n",
    "        print('error in calculation of acc')\n",
    "    sensitivity = tp/(tp+fn) #also called recall, True Positive Rate\n",
    "    specificity = tn/(tn+fp)\n",
    "    precision = tp/(tp+fp)\n",
    "    accuracy = (tp+tn)/number_datapoints\n",
    "    return accuracy, sensitivity, specificity,precision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc, sens, spec, prec = acc_sens_spec_prec(solution=solution, pos_represent=2, neg_represent=1)\n",
    "print(acc_sens_spec_prec(solution=solution, pos_represent=2, neg_represent=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
