{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "097d5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"w\") as file:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95efdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table(dataset_list, alias_dict, clean_dict):\n",
    "    for dataset in dataset_list:\n",
    "        orig_data = pd.read_csv(f\"../datasets/{dataset}/adult.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "        alias = alias_dict[dataset]\n",
    "        clean_name = clean_dict[dataset]\n",
    "\n",
    "        # rows, columns = df.shape\n",
    "\n",
    "        datapoints = orig_data.shape[0]\n",
    "        feat_orig = orig_data.shape[1]-1\n",
    "\n",
    "        bin_data = pd.read_csv(f\"../datasets/{dataset}/{dataset}_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "        feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "        number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "        with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "            #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "            file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "38fbe038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/adult/adult.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'adult'\n",
    "clean_name = 'adult'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/adult/stacked.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "datapoints = bin_data.shape[0]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "21e6c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#breast+cancer+wisconsin+diagnostic\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/breast+cancer+wisconsin+diagnostic/wdbc.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'wdbc'\n",
    "clean_name = 'breast cancer wisconsin diagnostic'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/breast+cancer+wisconsin+diagnostic/wdbc_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7854ed24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\_'\n",
      "/tmp/ipykernel_97877/3987071240.py:5: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  alias = 'car\\_eval'\n"
     ]
    }
   ],
   "source": [
    "#car_eval\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/car_evaluation/car.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'car\\_eval'\n",
    "clean_name = 'car evaluation'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/car_evaluation/car_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "db491ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mushroom\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/mushroom/agaricus-lepiota.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'mushroom'\n",
    "clean_name = 'agaricus-lepiota'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/mushroom/agaricus_lepiota_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a5c49975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nursery\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/nursery/nursery.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'nursery'\n",
    "clean_name = 'nursery'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/nursery/nursery_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fc1a4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seismic\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/seismic/seismic_data.txt\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'seismic'\n",
    "clean_name = 'seismic'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/seismic/seismic_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0a473a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spambase\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/spambase/spambase.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'spambase'\n",
    "clean_name = 'spambase'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/spambase/spambase_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "bac4a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wine\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/wine/wine.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'wine'\n",
    "clean_name = 'wine'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/wine/wine_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "dcdb542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# banknote+authentication\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/banknote+authentication/data_banknote_authentication.txt\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'banknote'\n",
    "clean_name = 'banknote authentication'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/banknote+authentication/banknote_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d996e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chess+king+rook+vs+king+pawn\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/chess+king+rook+vs+king+pawn/kr-vs-kp.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'chess'\n",
    "clean_name = 'chess king rook vs. king pawn'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "datapoints = orig_data.shape[0]\n",
    "feat_orig = orig_data.shape[1]-1 #account for target vars\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/chess+king+rook+vs+king+pawn/kr-vs-kp_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "aa40eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names = ['breast+cancer+wisconsin+diagnostic', 'car_evaluation', 'mushroom', 'nursery', 'seismic', 'spambase', 'wine', 'banknote+authentication', 'chess+king+rook+vs+king+pawn']\n",
    "\n",
    "alias_dict = {\n",
    "    #'adult' : 'adult',\n",
    "    #'breast+cancer+wisconsin+diagnostic' : 'bcwd',\n",
    "    #'car_evaluation' : 'car_eval',\n",
    "    #'mushroom' : 'mushroom',\n",
    "    #'nursery' : 'nursery',\n",
    "    #'seismic' : 'seismic',\n",
    "    #'spambase' : 'spambase',\n",
    "    #'wine' : 'wine',\n",
    "    #'banknote+authentication' : 'banknote',\n",
    "    #'chess+king+rook+vs+king+pawn' : 'chess',\n",
    "    #'monk1' : 'monk1',\n",
    "    #'monk2' : 'monk2',\n",
    "    #'monk3' : 'monk3'\n",
    "}\n",
    "\n",
    "clean_dict = {\n",
    "    'adult' : 'adult',\n",
    "    'breast+cancer+wisconsin+diagnostic' : 'breast cancer wisconsin diagnostic',\n",
    "    'car_evaluation' : 'car evalualtion',\n",
    "    'mushroom' : 'mushroom',\n",
    "    'nursery' : 'nursery',\n",
    "    'seismic' : 'seismic',\n",
    "    'spambase' : 'spambase',\n",
    "    'wine' : 'wine',\n",
    "    'banknote+authentication' : 'banknote',\n",
    "    'chess+king+rook+vs+king+pawn' : 'king rook vs. king pawn',\n",
    "    'monk1' : 'monk1',\n",
    "    'monk2' : 'monk2',\n",
    "    'monk3' : 'monk3'\n",
    "}\n",
    "\n",
    "#build_table(list_names, alias_dict, clean_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a2477174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monk1\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/monk+s+problems/monks-1.train\", sep=' ', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'monk1'\n",
    "clean_name = 'monk1'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "\n",
    "feat_orig = orig_data.shape[1]-2\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/monk1/monk1_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "datapoints = bin_data.shape[0]-1\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b6e98fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monk2\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/monk+s+problems/monks-2.train\", sep=' ', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'monk2'\n",
    "clean_name = 'monk2'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "\n",
    "feat_orig = orig_data.shape[1]-2\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/monk2/monk2_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "datapoints = bin_data.shape[0]-1\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "dfc67c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monk3\n",
    "\n",
    "orig_data = pd.read_csv(\"../datasets/monk+s+problems/monks-3.train\", sep=' ', skipinitialspace=True, header=None)\n",
    "\n",
    "alias = 'monk3'\n",
    "clean_name = 'monk3'\n",
    "\n",
    "# rows, columns = df.shape\n",
    "\n",
    "\n",
    "feat_orig = orig_data.shape[1]-2\n",
    "\n",
    "bin_data = pd.read_csv(\"../datasets/monk3/monk3_bin.csv\", sep=',', skipinitialspace=True)\n",
    "\n",
    "datapoints = bin_data.shape[0]-1\n",
    "\n",
    "feat_bin= bin_data.shape[1]-1\n",
    "\n",
    "number_target_classes = len(bin_data['y'].unique())\n",
    "\n",
    "with open(\"dataset_prop_table.txt\", \"a\") as file:\n",
    "    #alias, name, num_class, num_datap, num_feat_orig, num_feat_bin\n",
    "    file.write(f\"{alias} & {clean_name} & {number_target_classes} & {datapoints} & {feat_orig} & {feat_bin}\\\\\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
