{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0f14adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.ensemble import BaseEnsemble\n",
    "from scipy.stats import mode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827adbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rolling_lookahead_dt_pulp import rollo_oct_pulp\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "#from rolling_lookahead_dt_pulp.oct.optimal_tree_pulp import predict_model_pulp\n",
    "\n",
    "from rolling_lookahead_dt_pulp.rolling_tree.rolling_optimize_pulp import rolling_optimize_pulp\n",
    "from rolling_lookahead_dt_pulp.oct.tree import *\n",
    "from rolling_lookahead_dt_pulp.oct.optimal_tree_pulp import *\n",
    "from helpers.helpers import preprocess_dataframes\n",
    "\n",
    "# was hiermit eben nicht geht ist, dass man auf Trainingsdaten trainiert (was einem das reine Modell geben sollte). Dabei werden aber leider gleichzeitig\n",
    "# die Testdaten auf diesen Modell predicted\n",
    "# Das Resultat ist also, dass man nicht andere Testdaten auf dem fertigen modell testen kann\n",
    "\n",
    "class CustomTreeWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, train_data, test_data, depth=None, criterion='gini', target_label=None, features=None, time_limit = 1800, big_m = 99):\n",
    "        self.depth = depth\n",
    "        self.criterion = criterion\n",
    "        self.test_data = test_data\n",
    "        self.train_data = train_data\n",
    "        self.target_label = target_label\n",
    "        self.features = features\n",
    "        self.time_limit = time_limit\n",
    "        self.big_m = big_m\n",
    "        self.construct()\n",
    "\n",
    "    def construct(self):\n",
    "        train, test = preprocess_dataframes( #./rollo_oct/utils/helpers.py\n",
    "        train_df = self.train_data,\n",
    "        test_df = self.test_data,\n",
    "        target_label = self.target_label,\n",
    "        features = self.features)\n",
    "\n",
    "        df = pd.concat([train, test])\n",
    "        self.P = [int(i) for i in\n",
    "            list(train.loc[:, train.columns != 'y'].columns)]\n",
    "        train.columns = [\"y\", *self.P]\n",
    "        test.columns = [\"y\", *self.P]\n",
    "        self.K = sorted(list(set(df.y)))\n",
    "\n",
    "        self.result_dict = {} #adding dict to store solutions for every level\n",
    "        self.result_dict['tree'] = {}\n",
    "        self.result_dict['tree'][2] = {}\n",
    "        \n",
    "        # generate model\n",
    "        self.main_model = generate_model_pulp(P=self.P, K=self.K, data=train, y_idx=0, big_m=self.big_m, criterion=self.criterion)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.train_data = pd.concat([y, X], axis=1, ignore_index=False)\n",
    "\n",
    "        train, test = preprocess_dataframes( #./rollo_oct/utils/helpers.py\n",
    "                                            train_df = self.train_data,\n",
    "                                            test_df = self.test_data,\n",
    "                                            target_label = self.target_label,\n",
    "                                            features = self.features)\n",
    "        \n",
    "        self.P = [int(i) for i in \n",
    "            list(train.loc[:, train.columns != 'y'].columns)]\n",
    "        \n",
    "        self.main_model = train_model_pulp(model_dict=self.main_model, data=train, P=self.P)\n",
    "\n",
    "        self.result_dict['tree'][2]['trained_dict'] = self.main_model\n",
    "\n",
    "        # predict model\n",
    "        result_train = predict_model_pulp(data=train, model_dict=self.main_model, P=self.P)\n",
    "\n",
    "        misclassified_leafs = find_misclassification(df=result_train)\n",
    "\n",
    "        result_test = predict_model_pulp(data=test, model_dict=self.main_model, P=self.P)\n",
    "        \n",
    "        \n",
    "        train_acc = len(result_train.loc[result_train[\"prediction\"] == result_train[\"y\"]]) / \\\n",
    "                    len(result_train[\"y\"])\n",
    "\n",
    "        test_acc = len(result_test.loc[result_test[\"prediction\"] == result_test[\"y\"]]) / \\\n",
    "                len(result_test[\"y\"])\n",
    "        \n",
    "        \n",
    "        self.result_dict['tree'][2]['train'] = result_train[['y', 'prediction', 'leaf']]\n",
    "        self.result_dict['tree'][2]['test'] = result_test[['y', 'prediction', 'leaf']]\n",
    "\n",
    "        self.result_dict[2] = {\n",
    "        \"training_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc\n",
    "        }\n",
    "\n",
    "        train = train.drop([\"prediction\", \"leaf\"], axis=1)\n",
    "        test = test.drop([\"prediction\", \"leaf\"], axis=1)\n",
    "\n",
    "        if self.depth > 2:\n",
    "            self.result_dict = rolling_optimize_pulp(predefined_model=self.main_model,\n",
    "                                            train_data=train,\n",
    "                                            test_data=test,\n",
    "                                            main_depth=2,\n",
    "                                            target_depth=self.depth,\n",
    "                                            features=self.P,\n",
    "                                            time_limit=self.time_limit,\n",
    "                                            to_go_deep_nodes=misclassified_leafs,\n",
    "                                            result_dict=self.result_dict,\n",
    "                                            criterion=self.criterion)\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "\n",
    "        #print(X)\n",
    "\n",
    "        model_dict = self.result_dict['tree'][self.depth]['trained_dict']\n",
    "\n",
    "        dummy = pd.DataFrame({'y': [None]*len(X)}, index=X.index)\n",
    "\n",
    "        test = pd.concat([dummy, X], axis=1)\n",
    "\n",
    "        #print(test)\n",
    "\n",
    "        res = predict_model_pulp(data=test, model_dict=model_dict, P=self.P)\n",
    "\n",
    "        #print(res)\n",
    "        \n",
    "        preds = res['prediction']\n",
    "        if preds is None:\n",
    "            raise RuntimeError(\"No stored predictions found. Run fit first.\")\n",
    "        \n",
    "        #check = self.result_dict['tree'][self.depth]['test']\n",
    "        #check = check.drop(columns=['y', 'leaf'])\n",
    "        #print(check)\n",
    "\n",
    "        #print(preds.equals(check['prediction']))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1e744f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass CustomRandomForest(BaseEnsemble, ClassifierMixin):\\n    def __init__(self, base_estimator=None, n_estimators=10, max_depth=None, random_state=None):\\n        super().__init__(\\n            base_estimator=base_estimator,\\n            n_estimators=n_estimators,\\n            random_state=random_state,\\n        )\\n        self.max_depth = max_depth\\n\\n    def _validate_estimators(self):\\n        # This ensures base_estimator is cloned n_estimators times\\n        super()._validate_estimators()\\n        if self.base_estimator is None:\\n            self.base_estimator = CustomTreeClassifier(max_depth=self.max_depth)\\n\\n    def fit(self, X, y):\\n        self._validate_estimators()\\n        self.estimators_ = []\\n        n_samples = X.shape[0]\\n        rng = np.random.RandomState(self.random_state)\\n\\n        for i in range(self.n_estimators):\\n            # Bootstrap sample indices\\n            indices = rng.choice(n_samples, size=n_samples, replace=True)\\n            X_sample, y_sample = X[indices], y[indices]\\n            estimator = clone(self.base_estimator)\\n            estimator.fit(X_sample, y_sample)\\n            self.estimators_.append(estimator)\\n        return self\\n\\n    def predict(self, X):\\n        # Gather predictions from all trees\\n        predictions = np.array([tree.predict(X) for tree in self.estimators_])\\n        maj_vote, _ = mode(predictions, axis=0)\\n        return maj_vote.ravel()\\n        '"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class CustomRandomForest(BaseEnsemble, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=None, n_estimators=10, max_depth=None, random_state=None):\n",
    "        super().__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def _validate_estimators(self):\n",
    "        # This ensures base_estimator is cloned n_estimators times\n",
    "        super()._validate_estimators()\n",
    "        if self.base_estimator is None:\n",
    "            self.base_estimator = CustomTreeClassifier(max_depth=self.max_depth)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._validate_estimators()\n",
    "        self.estimators_ = []\n",
    "        n_samples = X.shape[0]\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            # Bootstrap sample indices\n",
    "            indices = rng.choice(n_samples, size=n_samples, replace=True)\n",
    "            X_sample, y_sample = X[indices], y[indices]\n",
    "            estimator = clone(self.base_estimator)\n",
    "            estimator.fit(X_sample, y_sample)\n",
    "            self.estimators_.append(estimator)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Gather predictions from all trees\n",
    "        predictions = np.array([tree.predict(X) for tree in self.estimators_])\n",
    "        maj_vote, _ = mode(predictions, axis=0)\n",
    "        return maj_vote.ravel()\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# just archived\n",
    "class CustomRandomForest(BaseEnsemble, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=None, n_estimators=10, max_depth=None, \n",
    "                 random_state=None, test_data=None, target_label=None, features=None, criterion='gini'):\n",
    "        super().__init__(n_estimators=n_estimators)\n",
    "        self.random_state = random_state  # we store this ourselves\n",
    "        self.base_estimator = base_estimator\n",
    "        self.max_depth = max_depth\n",
    "        self.test_data = test_data\n",
    "        self.target_label = target_label\n",
    "        self.features = features\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def _validate_estimators(self):\n",
    "        super()._validate_estimators()\n",
    "        # Provide default base_estimator if none given\n",
    "        if self.base_estimator is None:\n",
    "            self.base_estimator = CustomTreeWrapper(\n",
    "                depth=self.max_depth,\n",
    "                criterion=self.criterion,\n",
    "                test_data=self.test_data,\n",
    "                target_label=self.target_label,\n",
    "                features=self.features,\n",
    "            )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._validate_estimators()\n",
    "        self.estimators_ = []\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Bootstrap sample indices\n",
    "            indices = rng.choice(n_samples, size=n_samples, replace=True)\n",
    "            X_sample, y_sample = X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "            # Clone base estimator to get fresh copy\n",
    "            estimator = clone(self.base_estimator)\n",
    "            estimator.fit(X_sample, y_sample)\n",
    "            self.estimators_.append(estimator)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'estimators_')\n",
    "        \n",
    "        # Collect predictions from each tree\n",
    "        predictions = np.array([tree.predict(X) for tree in self.estimators_])\n",
    "        \n",
    "        \n",
    "        # Majority vote along first axis (trees)\n",
    "        maj_vote, _ = mode(predictions, axis=0)\n",
    "        return maj_vote.ravel()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8f14aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_seismic = pd.read_csv(\"datasets/seismic/seismic_bin.csv\")\n",
    "\n",
    "\n",
    "X = data_seismic.drop(columns=['y'])  # All columns except the target\n",
    "y = data_seismic['y']                 # Only the target column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, stratify=y, random_state=42)\n",
    "\n",
    "stacked_train = pd.concat([y_train, X_train], axis=1, ignore_index=False)\n",
    "stacked_test = pd.concat([y_test, X_test],axis=1, ignore_index=False)\n",
    "\n",
    "train_data = stacked_train\n",
    "test_data = stacked_test\n",
    "\n",
    "#feature_columns = train_data.columns[1:]\n",
    "\n",
    "feature_columns = X_train.columns\n",
    "#print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9445631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_nodes': [4, 5, 6, 7], 'leaf_nodes_path': {4: [1, 1], 5: [1, 0], 6: [0, 1], 7: [0, 0]}}\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/.venv/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/linux/i64/cbc /tmp/7f538600bcdc49f2bce6e6706ceda76a-pulp.mps -sec 1800 -timeMode elapsed -branch -printingOptions all -solution /tmp/7f538600bcdc49f2bce6e6706ceda76a-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 54 COLUMNS\n",
      "At line 22109 RHS\n",
      "At line 22159 BOUNDS\n",
      "At line 26578 ENDATA\n",
      "Problem MODEL has 49 rows, 4418 columns and 8836 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 1800\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 0.112518 - 0.00 seconds\n",
      "Cgl0004I processed model has 0 rows, 0 columns (0 integer (0 of which binary)) and 0 elements\n",
      "Cbc3007W No integer variables - nothing to do\n",
      "Cuts at root node changed objective from 0.112518 to -1.79769e+308\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                0.11251788\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.01\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/rolling_lookahead_dt_restructured/rolling_lookahead_dt_pulp/oct/optimal_tree_pulp.py:314: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = np.array(i[P]) #array of all feature values \\in {0,1} of that row\n",
      "/home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/rolling_lookahead_dt_restructured/rolling_lookahead_dt_pulp/oct/optimal_tree_pulp.py:314: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = np.array(i[P]) #array of all feature values \\in {0,1} of that row\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_nodes': [4, 5, 6, 7], 'leaf_nodes_path': {4: [1, 1], 5: [1, 0], 6: [0, 1], 7: [0, 0]}}\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/.venv/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/linux/i64/cbc /tmp/a9612d2826f74a32babbd626729d7ce2-pulp.mps -sec 1800 -timeMode elapsed -branch -printingOptions all -solution /tmp/a9612d2826f74a32babbd626729d7ce2-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 54 COLUMNS\n",
      "At line 22119 RHS\n",
      "At line 22169 BOUNDS\n",
      "At line 26588 ENDATA\n",
      "Problem MODEL has 49 rows, 4418 columns and 8836 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 1800\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 0.240947 - 0.00 seconds\n",
      "Cgl0004I processed model has 0 rows, 0 columns (0 integer (0 of which binary)) and 0 elements\n",
      "Cbc3007W No integer variables - nothing to do\n",
      "Cuts at root node changed objective from 0.240947 to -1.79769e+308\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                0.24094721\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.01\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.02   (Wallclock seconds):       0.02\n",
      "\n",
      "{'leaf_nodes': [4, 5, 6, 7], 'leaf_nodes_path': {4: [1, 1], 5: [1, 0], 6: [0, 1], 7: [0, 0]}}\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/.venv/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/linux/i64/cbc /tmp/b794b62bdd6b4f12b933a014dcbc9f62-pulp.mps -sec 1800 -timeMode elapsed -branch -printingOptions all -solution /tmp/b794b62bdd6b4f12b933a014dcbc9f62-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 54 COLUMNS\n",
      "At line 22081 RHS\n",
      "At line 22131 BOUNDS\n",
      "At line 26550 ENDATA\n",
      "Problem MODEL has 49 rows, 4418 columns and 8836 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 1800\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 0.0768941 - 0.00 seconds\n",
      "Cgl0004I processed model has 0 rows, 0 columns (0 integer (0 of which binary)) and 0 elements\n",
      "Cbc3007W No integer variables - nothing to do\n",
      "Cuts at root node changed objective from 0.0768941 to -1.79769e+308\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                0.07689415\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.01\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/rolling_lookahead_dt_restructured/rolling_lookahead_dt_pulp/oct/optimal_tree_pulp.py:314: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = np.array(i[P]) #array of all feature values \\in {0,1} of that row\n",
      "/home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/rolling_lookahead_dt_restructured/rolling_lookahead_dt_pulp/oct/optimal_tree_pulp.py:314: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = np.array(i[P]) #array of all feature values \\in {0,1} of that row\n"
     ]
    }
   ],
   "source": [
    "# Usage outside:\n",
    "wrapper = CustomTreeWrapper(\n",
    "    depth=3,\n",
    "    criterion='gini',\n",
    "    test_data=test_data,\n",
    "    train_data= train_data,\n",
    "    target_label='y',\n",
    "    features=feature_columns\n",
    ")\n",
    "wrapper.fit(X_train, y_train); #semicolon for suppressing when interactive environment (Jupyter) tries to display the returned object, suppresses repr(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3675b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660    1\n",
      "1216    1\n",
      "2483    1\n",
      "248     1\n",
      "455     1\n",
      "       ..\n",
      "21      1\n",
      "1073    1\n",
      "665     1\n",
      "1192    1\n",
      "1250    1\n",
      "Name: prediction, Length: 100, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drood/Obsidian/Files/Bachelorarbeit/rlrf_my_try/rolling_lookahead_dt_restructured/rolling_lookahead_dt_pulp/oct/optimal_tree_pulp.py:314: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = np.array(i[P]) #array of all feature values \\in {0,1} of that row\n"
     ]
    }
   ],
   "source": [
    "#predictions = wrapper.predict(test_data)\n",
    "predictions = wrapper.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9dc510a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Instantiate custom random forest using same test data fixed at construction\\nforest = CustomRandomForest(\\n    n_estimators=5,\\n    max_depth=3,\\n    random_state=42,\\n    test_data=test_data,\\n    target_label=\\'y\\',\\n    features=feature_columns,\\n    criterion=\\'gini\\',\\n)\\n# Fit on train data only - internally, each base estimator will use complete test data from constructor\\nforest.fit(X_train, y_train)\\n\\n# Predict on test data (must be the same test_data-frame used)\\nforest_preds = forest.predict(test_data[feature_columns])\\nprint(\"Random forest predictions:\", forest_preds)\\n'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Instantiate custom random forest using same test data fixed at construction\n",
    "forest = CustomRandomForest(\n",
    "    n_estimators=5,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    "    test_data=test_data,\n",
    "    target_label='y',\n",
    "    features=feature_columns,\n",
    "    criterion='gini',\n",
    ")\n",
    "# Fit on train data only - internally, each base estimator will use complete test data from constructor\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data (must be the same test_data-frame used)\n",
    "forest_preds = forest.predict(test_data[feature_columns])\n",
    "print(\"Random forest predictions:\", forest_preds)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
