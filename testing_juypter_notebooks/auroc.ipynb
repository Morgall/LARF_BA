{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d09337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Go up one directory to get to master/\n",
    "project_root = str(Path.cwd().parent)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solutions_all_folds_rollOCT(name_dataset: str, depth=3, folds_available = 10) -> dict: #for 10 fold cross valdidation, carefull that trees have min depth 2\n",
    "    sol_dict = {} # one entry for every fold, [fold][depth]['test'] for train_data classification for fold of depth; same for training\n",
    "    for i in range(1,folds_available+1):\n",
    "        sol_dict[i] = {}\n",
    "        for j in range(2,depth+1):\n",
    "            sol_dict[i][j] = {}\n",
    "            sol_dict[i][j]['test'] = pd.read_csv(f\"../results/{name_dataset}/pulp/fold{i}/depth{j}_classification_{name_dataset}_test.csv\")\n",
    "            sol_dict[i][j]['train'] = pd.read_csv(f\"../results/{name_dataset}/pulp/fold{i}/depth{j}_classification_{name_dataset}_train.csv\")\n",
    "    return sol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solutions_all_folds_cart(name_dataset: str, depth=3, folds_available = 10) -> dict: #for 10 fold cross valdidation, carefull that trees have min depth 2\n",
    "    sol_dict = {} # one entry for every fold, [fold][depth]['test'] for train_data classification for fold of depth; same for training\n",
    "    for i in range(1,folds_available+1):\n",
    "        sol_dict[i] = {}\n",
    "        for j in range(2,depth+1):\n",
    "            sol_dict[i][j] = {}\n",
    "            sol_dict[i][j]['test'] = pd.read_csv(f\"../results/{name_dataset}/cart/fold{i}/depth{j}_classification_{name_dataset}_test.csv\")\n",
    "            sol_dict[i][j]['train'] = pd.read_csv(f\"../results/{name_dataset}/cart/fold{i}/depth{j}_classification_{name_dataset}_train.csv\")\n",
    "    return sol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, matthews_corrcoef, roc_auc_score, f1_score\n",
    "\n",
    "# does not contain time stuff\n",
    "# man muss Ã¼ber die target vars iterieren\n",
    "# we want result_dict[depth]['test'/'train'][target_var] and then sens,spec,prec,acc dor all folds. Then we are able to combine it with original target var afterwards\n",
    "def solutions_all_depths_all_folds_multiclass(dataset_name, list_target_vars, max_tree_depth, folds_available, cart = False):\n",
    "    if cart == False:\n",
    "        sol_dict = get_solutions_all_folds_rollOCT(name_dataset = dataset_name, depth=max_tree_depth, folds_available = folds_available)\n",
    "    else:\n",
    "        sol_dict = get_solutions_all_folds_cart(name_dataset = dataset_name, depth=max_tree_depth, folds_available = folds_available)\n",
    "    result_dict = dict()\n",
    "    for depth in range(2,max_tree_depth+1):\n",
    "        result_dict[depth] = dict()\n",
    "        result_dict[depth]['test'] = dict()\n",
    "        result_dict[depth]['train'] = dict()\n",
    "\n",
    "        acc_list_test = []\n",
    "        prec_list_test = []\n",
    "        recall_list_test = []\n",
    "        mcc_list_test = []\n",
    "        roc_auc_list_test = []\n",
    "        f1_list_test = []\n",
    "\n",
    "        acc_list_train = []\n",
    "        prec_list_train = []\n",
    "        recall_list_train = []\n",
    "        mcc_list_train = []\n",
    "        roc_auc_list_train = []\n",
    "        f1_list_train = []\n",
    "\n",
    "\n",
    "        for fold in range(1, folds_available+1):\n",
    "            \n",
    "            y_true_test = sol_dict[fold][depth]['test']['y']\n",
    "            y_predict_test = sol_dict[fold][depth]['test']['prediction']\n",
    "\n",
    "            y_true_train = sol_dict[fold][depth]['train']['y']\n",
    "            y_predict_train = sol_dict[fold][depth]['train']['prediction']\n",
    "\n",
    "            acc_list_test.append(accuracy_score(y_true_test, y_predict_test))\n",
    "            prec_list_test.append(precision_score(y_true_test, y_predict_test))\n",
    "            recall_list_test.append(recall_score(y_true_test, y_predict_test))\n",
    "            mcc_list_test.append(matthews_corrcoef(y_true_test, y_predict_test))\n",
    "            roc_auc_list_test.append(roc_auc_score(y_true_test, y_predict_test, multi_class='ovr', average='macro'))\n",
    "            f1_list_test.append(f1_score(y_true_test, y_predict_test))\n",
    "\n",
    "            acc_list_train.append(accuracy_score(y_true_train, y_predict_train))\n",
    "            prec_list_train.append(precision_score(y_true_test, y_predict_test))\n",
    "            recall_list_train.append(recall_score(y_true_test, y_predict_test))\n",
    "            mcc_list_train.append(matthews_corrcoef(y_true_test, y_predict_test))\n",
    "            roc_auc_list_train.append(roc_auc_score(y_true_test, y_predict_test, multi_class='ovr', average='macro'))\n",
    "            f1_list_train.append(f1_score(y_true_test, y_predict_test))\n",
    "            \n",
    "\n",
    "        result_dict[depth]['test']['mcc'] = mean_mcc_test\n",
    "        result_dict[depth]['train']['mcc'] = mean_mcc_train\n",
    "\n",
    "        #std_mcc_test = np.std(mcc_scores_test)\n",
    "        #std_mcc_train = np.std(mcc_scores_train)\n",
    "\n",
    "    \n",
    "    return result_dict"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
