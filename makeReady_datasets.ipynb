{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0e8851",
   "metadata": {},
   "source": [
    "Hier alle vorbereitungen für x-fold cross validation inkl. dem anschließenden spreichern der vorbereiteten binarized datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d97db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from helpers.helpers import preprocess_numerical, move_targets_to_front_and_rename, make_data_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454ef72",
   "metadata": {},
   "source": [
    "# test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ce0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"datasets/example_datasets/train.csv\")\n",
    "test_data = pd.read_csv(\"datasets/example_datasets/test.csv\")\n",
    "\n",
    "stacked = pd.concat([train_data, test_data ], ignore_index=False)\n",
    "\n",
    "stacked.to_csv('datasets/example_datasets/stacked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97bcf0",
   "metadata": {},
   "source": [
    "# adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1484d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K']\n",
      "       y  1  2  3  4  5  6  7  8  9  ...  115  116  117  118  119  120  121  \\\n",
      "0      1  1  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "1      1  1  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "2      1  1  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "3      1  1  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "4      1  0  1  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "...   .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "16276  1  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "16277  1  1  0  0  1  0  1  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "16278  1  1  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "16279  1  1  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "16280  2  1  1  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "\n",
      "       122  123  124  \n",
      "0        1    0    0  \n",
      "1        1    0    0  \n",
      "2        1    0    0  \n",
      "3        1    0    0  \n",
      "4        0    0    0  \n",
      "...    ...  ...  ...  \n",
      "16276    1    0    0  \n",
      "16277    1    0    0  \n",
      "16278    1    0    0  \n",
      "16279    1    0    0  \n",
      "16280    1    0    0  \n",
      "\n",
      "[48842 rows x 125 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load your training and test datasets\n",
    "train_data = pd.read_csv(\"datasets/adult/adult.data\", sep=',', skipinitialspace=True, header=None) #32561 rows\n",
    "test_data = pd.read_csv(\"datasets/adult/adult.test\", sep=',', skipinitialspace=True, header=None) #16281 rows\n",
    "\n",
    "\n",
    "# Remove dots from the 'target' column\n",
    "test_data[14] = test_data[14].astype(str).str.replace('.', '', regex=False)\n",
    "\n",
    "len_train_data = len(train_data)\n",
    "\n",
    "stacked = pd.concat([train_data, test_data ], ignore_index=False)\n",
    "#print(stacked)\n",
    "\n",
    "\n",
    "stacked = preprocess_numerical(stacked)\n",
    "stacked = move_targets_to_front_and_rename(data= stacked, target_label=14)\n",
    "\n",
    "unique_values = stacked ['y'].unique()\n",
    "print(unique_values) # hier sieht man dann, dass es einen zusätzlichen punkt bei den target labels in adult.test gibt; also ohne löschen des punktes\n",
    "\n",
    "\n",
    "\n",
    "stacked = make_data_binary(stacked)\n",
    "print(stacked)\n",
    "stacked.to_csv('datasets/adult/stacked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8381195",
   "metadata": {},
   "source": [
    "car eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b5dd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unacc' 'acc' 'vgood' 'good']\n",
      "      y  1  2  3  4  5  6  7  8  9  ...  12  13  14  15  16  17  18  19  20  \\\n",
      "0     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   0   1   0   1   \n",
      "1     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   0   1   0   0   \n",
      "2     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   0   1   1   0   \n",
      "3     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   1   0   0   1   \n",
      "4     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   1   0   0   0   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
      "1723  2  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   0   1   0   0   0   \n",
      "1724  4  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   0   1   0   1   0   \n",
      "1725  3  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   1   0   0   0   1   \n",
      "1726  2  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   1   0   0   0   0   \n",
      "1727  4  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   1   0   0   1   0   \n",
      "\n",
      "      21  \n",
      "0      0  \n",
      "1      1  \n",
      "2      0  \n",
      "3      0  \n",
      "4      1  \n",
      "...   ..  \n",
      "1723   1  \n",
      "1724   0  \n",
      "1725   0  \n",
      "1726   1  \n",
      "1727   0  \n",
      "\n",
      "[1728 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/car_evaluation/car.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "data = preprocess_numerical(data)\n",
    "data = move_targets_to_front_and_rename(data= data, target_label=6)\n",
    "\n",
    "unique_values = data['y'].unique()\n",
    "print(unique_values) # hier sieht man dann, dass es einen zusätzlichen punkt bei den target labels in adult.test gibt; also ohne löschen des punktes\n",
    "\n",
    "\n",
    "\n",
    "data = make_data_binary(data)\n",
    "print(data)\n",
    "data.to_csv('datasets/car_evaluation/car_bin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f65c7",
   "metadata": {},
   "source": [
    "seismic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datasets/seismic/seismic_data.txt\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "data = preprocess_numerical(data)\n",
    "data = move_targets_to_front_and_rename(data= data, target_label=18)\n",
    "\n",
    "unique_values = data['y'].unique()\n",
    "print(unique_values) # hier sieht man dann, dass es einen zusätzlichen punkt bei den target labels in adult.test gibt; also ohne löschen des punktes\n",
    "\n",
    "\n",
    "\n",
    "data = make_data_binary(data)\n",
    "print(data)\n",
    "data.to_csv('datasets/seismic/seismic_bin.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
