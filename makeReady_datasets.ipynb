{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0e8851",
   "metadata": {},
   "source": [
    "Hier alle vorbereitungen für x-fold cross validation inkl. dem anschließenden spreichern der vorbereiteten binarized datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d97db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from helpers.helpers import preprocess_numerical, move_targets_to_front_and_rename, make_data_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454ef72",
   "metadata": {},
   "source": [
    "# test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"datasets/example_datasets/train.csv\")\n",
    "test_data = pd.read_csv(\"datasets/example_datasets/test.csv\")\n",
    "\n",
    "stacked = pd.concat([train_data, test_data], ignore_index=False)\n",
    "\n",
    "#stacked.to_csv('datasets/example_datasets/stacked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97bcf0",
   "metadata": {},
   "source": [
    "# adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1484d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K']\n",
      "       y  1  2  3  4  5  6  7  8  9  ...  112  113  114  115  116  117  118  \\\n",
      "0      1  1  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "1      1  1  0  0  0  1  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "2      1  1  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "3      1  1  0  0  0  0  1  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "4      1  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "...   .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "16276  1  0  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "16277  1  1  0  0  0  0  1  1  0  0  ...    0    0    0    0    0    0    0   \n",
      "16278  1  1  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "16279  1  1  0  0  0  1  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "16280  2  1  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "\n",
      "       119  120  121  \n",
      "0        1    0    0  \n",
      "1        1    0    0  \n",
      "2        1    0    0  \n",
      "3        1    0    0  \n",
      "4        0    0    0  \n",
      "...    ...  ...  ...  \n",
      "16276    1    0    0  \n",
      "16277    1    0    0  \n",
      "16278    1    0    0  \n",
      "16279    1    0    0  \n",
      "16280    1    0    0  \n",
      "\n",
      "[48842 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load your training and test datasets\n",
    "train_data = pd.read_csv(\"datasets/adult/adult.data\", sep=',', skipinitialspace=True, header=None) #32561 rows\n",
    "test_data = pd.read_csv(\"datasets/adult/adult.test\", sep=',', skipinitialspace=True, header=None) #16281 rows\n",
    "\n",
    "\n",
    "# Remove dots from the 'target' column\n",
    "test_data[14] = test_data[14].astype(str).str.replace('.', '', regex=False)\n",
    "\n",
    "len_train_data = len(train_data)\n",
    "\n",
    "stacked = pd.concat([train_data, test_data ], ignore_index=False)\n",
    "#print(stacked)\n",
    "\n",
    "\n",
    "stacked = preprocess_numerical(stacked, target_label=14)\n",
    "stacked = move_targets_to_front_and_rename(data= stacked, target_label=14)\n",
    "\n",
    "unique_values = stacked ['y'].unique()\n",
    "print(unique_values) # hier sieht man dann, dass es einen zusätzlichen punkt bei den target labels in adult.test gibt; also ohne löschen des punktes\n",
    "\n",
    "\n",
    "\n",
    "stacked = make_data_binary(stacked)\n",
    "print(stacked)\n",
    "#stacked.to_csv('datasets/adult/stacked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8381195",
   "metadata": {},
   "source": [
    "# car eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5dd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unacc' 'acc' 'vgood' 'good']\n",
      "      y  1  2  3  4  5  6  7  8  9  ...  12  13  14  15  16  17  18  19  20  \\\n",
      "0     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   0   1   0   1   \n",
      "1     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   0   1   0   0   \n",
      "2     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   0   1   1   0   \n",
      "3     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   1   0   0   1   \n",
      "4     3  0  0  0  1  0  0  0  1  1  ...   0   1   0   0   0   1   0   0   0   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
      "1723  2  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   0   1   0   0   0   \n",
      "1724  4  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   0   1   0   1   0   \n",
      "1725  3  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   1   0   0   0   1   \n",
      "1726  2  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   1   0   0   0   0   \n",
      "1727  4  0  1  0  0  0  1  0  0  0  ...   1   0   0   1   1   0   0   1   0   \n",
      "\n",
      "      21  \n",
      "0      0  \n",
      "1      1  \n",
      "2      0  \n",
      "3      0  \n",
      "4      1  \n",
      "...   ..  \n",
      "1723   1  \n",
      "1724   0  \n",
      "1725   0  \n",
      "1726   1  \n",
      "1727   0  \n",
      "\n",
      "[1728 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/car_evaluation/car.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "data = preprocess_numerical(data, target_label=6)\n",
    "data = move_targets_to_front_and_rename(data= data, target_label=6)\n",
    "\n",
    "unique_values = data['y'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "\n",
    "\n",
    "data = make_data_binary(data)\n",
    "print(data)\n",
    "#data.to_csv('datasets/car_evaluation/car_bin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f65c7",
   "metadata": {},
   "source": [
    "# seismic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "      y  1  2  3  4  5  6  7  8  9  ...  38  39  40  41  42  43  44  45  46  \\\n",
      "0     1  0  0  0  0  0  1  0  0  0  ...   0   1   1   1   1   0   0   1   0   \n",
      "1     1  0  0  0  0  0  1  0  0  0  ...   0   1   1   1   0   1   0   0   1   \n",
      "2     1  0  0  0  0  0  1  0  0  1  ...   0   1   1   1   1   0   0   1   0   \n",
      "3     1  0  0  0  0  0  1  0  0  0  ...   0   1   1   1   0   1   0   0   1   \n",
      "4     1  0  0  0  0  0  1  0  0  0  ...   0   1   1   1   1   0   0   1   0   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
      "2579  1  1  1  0  0  0  1  0  0  0  ...   0   1   1   1   1   0   0   1   0   \n",
      "2580  1  1  1  0  0  0  1  0  0  0  ...   0   1   1   1   1   0   0   1   0   \n",
      "2581  1  1  1  0  0  0  1  0  0  0  ...   0   1   1   1   1   0   0   1   0   \n",
      "2582  1  0  1  0  0  0  1  0  0  0  ...   0   1   1   1   1   0   0   1   0   \n",
      "2583  1  0  1  0  0  0  1  0  0  0  ...   0   1   1   1   1   0   0   1   0   \n",
      "\n",
      "      47  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "...   ..  \n",
      "2579   0  \n",
      "2580   0  \n",
      "2581   0  \n",
      "2582   0  \n",
      "2583   0  \n",
      "\n",
      "[2584 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/seismic/seismic_data.txt\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "data = preprocess_numerical(data, target_label=18)\n",
    "data = move_targets_to_front_and_rename(data= data, target_label=18)\n",
    "\n",
    "unique_values = data['y'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "\n",
    "\n",
    "data = make_data_binary(data)\n",
    "print(data)\n",
    "#data.to_csv('datasets/seismic/seismic_bin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39df9c",
   "metadata": {},
   "source": [
    "# wine\n",
    "\n",
    "Hier sieht man Problem, wenn cass identifier integers und nicht binary sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd657611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y  1  2  3  4  5  6  7  8  9  10  11  12  13\n",
      "0    1  4  1  3  0  4  3  4  1  4   3   2   4   4\n",
      "1    1  2  2  0  0  2  3  3  0  1   2   3   4   4\n",
      "2    1  2  3  4  2  2  3  4  1  4   3   2   3   4\n",
      "3    1  4  2  3  0  4  4  4  0  4   4   1   4   4\n",
      "4    1  2  3  4  3  4  3  3  2  3   2   2   3   2\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ..  ..  ..  ..\n",
      "173  3  3  4  3  3  2  1  0  4  0   4   0   0   2\n",
      "174  3  3  4  3  4  3  1  0  3  1   4   0   0   3\n",
      "175  3  2  4  1  2  4  0  0  3  1   4   0   0   3\n",
      "176  3  2  3  2  2  4  0  0  4  2   4   0   0   3\n",
      "177  3  4  4  4  4  2  1  0  4  1   4   0   0   1\n",
      "\n",
      "[178 rows x 14 columns]\n",
      "[1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nhier hat man gesehen, dass target vars auch categorical gemacht wurden, was zu problemen geführt hat.#\\nDas wurde mit der exclusion von der target label col in preprocess_numerical() behoben\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/wine/wine.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "data = preprocess_numerical(data, target_label=0)\n",
    "\n",
    "data = move_targets_to_front_and_rename(data= data, target_label=0)\n",
    "\n",
    "print(data)\n",
    "\n",
    "unique_values = data['y'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "\"\"\"\n",
    "hier hat man gesehen, dass target vars auch categorical gemacht wurden, was zu problemen geführt hat.#\n",
    "Das wurde mit der exclusion von der target label col in preprocess_numerical() behoben\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ece55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y  1  2  3  4  5  6  7  8  9  ...  56  57  58  59  60  61  62  63  64  65\n",
      "0    1  0  0  0  0  1  0  1  0  0  ...   0   0   0   0   1   0   0   0   0   1\n",
      "1    1  0  0  1  0  0  0  0  1  0  ...   0   0   0   0   1   0   0   0   0   1\n",
      "2    1  0  0  1  0  0  0  0  0  1  ...   0   0   0   1   0   0   0   0   0   1\n",
      "3    1  0  0  0  0  1  0  0  1  0  ...   0   0   0   0   1   0   0   0   0   1\n",
      "4    1  0  0  1  0  0  0  0  0  1  ...   0   0   0   1   0   0   0   1   0   0\n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "173  3  0  0  0  1  0  0  0  0  0  ...   1   0   0   0   0   0   0   1   0   0\n",
      "174  3  0  0  0  1  0  0  0  0  0  ...   1   0   0   0   0   0   0   0   1   0\n",
      "175  3  0  0  1  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   0   1   0\n",
      "176  3  0  0  1  0  0  0  0  0  1  ...   1   0   0   0   0   0   0   0   1   0\n",
      "177  3  0  0  0  0  1  0  0  0  0  ...   1   0   0   0   0   0   1   0   0   0\n",
      "\n",
      "[178 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "data = make_data_binary(data)\n",
    "print(data)\n",
    "\n",
    "#data.to_csv('datasets/wine/wine_bin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9e914",
   "metadata": {},
   "source": [
    "# spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983719a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "[1 0]\n",
      "      y  1  2  3  4  5  6  7  8  9  ...  73  74  75  76  77  78  79  80  81  \\\n",
      "0     2  0  0  0  0  1  0  1  0  0  ...   0   0   0   0   1   0   0   0   1   \n",
      "1     2  1  0  1  1  0  0  1  0  0  ...   0   0   0   0   1   0   0   0   0   \n",
      "2     2  0  1  1  0  0  0  1  0  0  ...   0   0   0   0   1   0   0   0   0   \n",
      "3     2  0  1  0  1  1  0  0  0  0  ...   0   0   0   1   0   0   0   0   1   \n",
      "4     2  0  1  0  1  1  0  0  0  0  ...   0   0   0   1   0   0   0   0   1   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
      "4596  1  1  0  1  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   1   0   \n",
      "4597  1  0  0  0  0  0  0  0  0  0  ...   1   0   0   0   0   1   0   0   0   \n",
      "4598  1  1  0  0  0  0  0  1  0  0  ...   0   1   0   0   0   0   0   1   0   \n",
      "4599  1  1  0  0  0  0  0  0  0  0  ...   1   0   0   0   0   0   0   1   0   \n",
      "4600  1  0  0  0  0  0  0  0  0  1  ...   1   0   0   0   0   0   1   0   0   \n",
      "\n",
      "      82  \n",
      "0      0  \n",
      "1      1  \n",
      "2      1  \n",
      "3      0  \n",
      "4      0  \n",
      "...   ..  \n",
      "4596   0  \n",
      "4597   0  \n",
      "4598   0  \n",
      "4599   0  \n",
      "4600   0  \n",
      "\n",
      "[4601 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/spambase/spambase.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "#num_columns = data.shape[1]\n",
    "#print(num_columns)\n",
    "\n",
    "num_rows = data.shape[0]\n",
    "print(num_rows)\n",
    "\n",
    "data = preprocess_numerical(data, target_label=57)\n",
    "\n",
    "data = move_targets_to_front_and_rename(data= data, target_label=57)\n",
    "\n",
    "unique_values = data['y'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "data = make_data_binary(data)\n",
    "print(data)\n",
    "\n",
    "#data.to_csv('datasets/spambase/spambase_bin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2712f",
   "metadata": {},
   "source": [
    "wisconsin breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'B']\n",
      "     y  1  2  3  4  5  6  7  8  9  ...  141  142  143  144  145  146  147  \\\n",
      "0    2  0  0  0  0  1  1  0  0  0  ...    0    0    0    0    1    0    0   \n",
      "1    2  0  0  0  0  1  0  1  0  0  ...    0    0    1    0    0    0    0   \n",
      "2    2  0  0  0  0  1  0  0  0  1  ...    0    0    0    0    1    0    0   \n",
      "3    2  0  1  0  0  0  0  0  0  1  ...    0    0    0    0    1    0    0   \n",
      "4    2  0  0  0  0  1  1  0  0  0  ...    1    0    0    0    0    0    1   \n",
      "..  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "564  2  0  0  0  0  1  0  0  0  1  ...    1    0    0    0    0    0    1   \n",
      "565  2  0  0  0  0  1  0  0  0  0  ...    0    1    0    0    0    1    0   \n",
      "566  2  0  0  0  1  0  0  0  0  0  ...    1    0    0    0    0    0    0   \n",
      "567  2  0  0  0  0  1  0  0  0  0  ...    0    0    0    0    1    0    0   \n",
      "568  1  1  0  0  0  0  0  0  0  0  ...    0    0    1    0    0    0    1   \n",
      "\n",
      "     148  149  150  \n",
      "0      0    0    1  \n",
      "1      0    1    0  \n",
      "2      0    1    0  \n",
      "3      0    0    1  \n",
      "4      0    0    0  \n",
      "..   ...  ...  ...  \n",
      "564    0    0    0  \n",
      "565    0    0    0  \n",
      "566    1    0    0  \n",
      "567    0    0    1  \n",
      "568    0    0    0  \n",
      "\n",
      "[569 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/breast+cancer+wisconsin+diagnostic/wdbc.data\", sep=',', skipinitialspace=True, header=None)\n",
    "\n",
    "data.drop(data.columns[0], axis=1, inplace=True) #drop the id col; result in col 0 not existing. Should get fixed during binaring\n",
    "#print(data)\n",
    "\n",
    "#num_columns = data.shape[1]\n",
    "#print(num_columns)\n",
    "\n",
    "#num_rows = data.shape[0]\n",
    "#print(num_rows)\n",
    "\n",
    "data = preprocess_numerical(data, target_label=1)\n",
    "\n",
    "data = move_targets_to_front_and_rename(data= data, target_label=1)\n",
    "\n",
    "unique_values = data['y'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "data = make_data_binary(data)\n",
    "print(data)\n",
    "\n",
    "#data.to_csv('datasets/breast+cancer+wisconsin+diagnostic/wdbc_bin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440799d",
   "metadata": {},
   "source": [
    "Nursery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e7135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
